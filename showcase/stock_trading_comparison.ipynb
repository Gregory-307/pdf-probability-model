{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost: Point Prediction vs Distribution Prediction\n",
    "\n",
    "**Pipeline 1**: XGBoost → single number (expected return)\n",
    "\n",
    "**Pipeline 2**: XGBoost → 4 numbers (NIG distribution parameters) → VaR filter\n",
    "\n",
    "Same features, same model architecture, different outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import temporalpdf as tpdf\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "\n",
    "COST_BPS = 2  # Transaction cost in basis points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path.cwd().parent / \"data\" / \"equity_returns.csv\")\n",
    "returns = df[\"return_pct\"].values\n",
    "print(f\"S&P 500: {len(returns):,} days\")\n",
    "\n",
    "# Create features from lookback window\n",
    "lookback = 20\n",
    "X, y = [], []\n",
    "for i in range(lookback, len(returns) - 1):\n",
    "    window = returns[i-lookback:i]\n",
    "    X.append([np.mean(window), np.std(window), window[-1], window[-2],\n",
    "              np.min(window), np.max(window), np.sum(window > 0) / lookback])\n",
    "    y.append(returns[i + 1])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Train/test split\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "print(f\"Train: {len(y_train):,}, Test: {len(y_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1: XGBoost → Point Prediction\n",
    "\n",
    "Model predicts next-day return. Decision: go long if prediction > 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_point = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "model_point.fit(X_train, y_train)\n",
    "pred_point = model_point.predict(X_test)\n",
    "\n",
    "decisions_p1 = pred_point > 0\n",
    "print(f\"Pipeline 1: {np.sum(decisions_p1)} / {len(y_test)} trades ({np.mean(decisions_p1):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 2: XGBoost → Distribution Parameters\n",
    "\n",
    "Model predicts NIG parameters (mu, delta, alpha, beta). Decision: go long if E[X] > 0 AND VaR(5%) > -2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution targets: fit NIG to each training window\n",
    "print(\"Fitting NIG distributions to training windows...\")\n",
    "param_targets = []\n",
    "for i in range(lookback, lookback + len(y_train)):\n",
    "    window = returns[i-lookback:i]\n",
    "    params = tpdf.fit_nig(window)  # Use library function\n",
    "    # Store in transformed space (log for positive params)\n",
    "    beta_ratio = np.clip(params.beta / params.alpha, -0.99, 0.99)\n",
    "    param_targets.append([\n",
    "        params.mu,\n",
    "        np.log(params.delta),\n",
    "        np.log(params.alpha),\n",
    "        np.arctanh(beta_ratio)\n",
    "    ])\n",
    "param_targets = np.array(param_targets)\n",
    "print(f\"Created {len(param_targets)} distribution targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model to predict distribution parameters\n",
    "model_dist = MultiOutputRegressor(\n",
    "    GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    ")\n",
    "model_dist.fit(X_train, param_targets)\n",
    "pred_params_raw = model_dist.predict(X_test)\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Make decisions from predicted distributions\nnig = tpdf.NIG()\nrng = np.random.default_rng(42)\ndecisions_p2 = []\nvar_estimates = []\n\nfor mu, log_delta, log_alpha, beta_raw in pred_params_raw:\n    delta = max(np.exp(log_delta), 0.01)\n    alpha = max(np.exp(log_alpha), 0.1)\n    beta = np.clip(alpha * np.tanh(beta_raw), -alpha + 0.01, alpha - 0.01)\n    \n    params = tpdf.NIGParameters(mu=mu, delta=delta, alpha=alpha, beta=beta)\n    samples = nig.sample(3000, 0, params, rng=rng)\n    \n    expected = np.mean(samples)\n    var_5 = -np.percentile(samples, 5)  # VaR as positive loss\n    var_estimates.append(var_5)\n    \n    # Decision: positive expected AND acceptable risk (VaR < 2%)\n    decisions_p2.append(expected > 0 and var_5 < 2.0)\n\ndecisions_p2 = np.array(decisions_p2)\nprint(f\"Pipeline 2: {np.sum(decisions_p2)} / {len(y_test)} trades ({np.mean(decisions_p2):.1%})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe(returns):\n",
    "    if np.std(returns) == 0: return 0\n",
    "    return np.mean(returns) / np.std(returns) * np.sqrt(252)\n",
    "\n",
    "def bootstrap_ci(returns, n=1000):\n",
    "    rng = np.random.default_rng(42)\n",
    "    sharpes = [sharpe(rng.choice(returns, len(returns), replace=True)) for _ in range(n)]\n",
    "    return np.percentile(sharpes, 2.5), np.percentile(sharpes, 97.5)\n",
    "\n",
    "cost = COST_BPS / 100\n",
    "strat_bh = y_test\n",
    "strat_p1 = np.where(decisions_p1, y_test - cost, 0)\n",
    "strat_p2 = np.where(decisions_p2, y_test - cost, 0)\n",
    "\n",
    "sharpe_bh, ci_bh = sharpe(strat_bh), bootstrap_ci(strat_bh)\n",
    "sharpe_p1, ci_p1 = sharpe(strat_p1), bootstrap_ci(strat_p1)\n",
    "sharpe_p2, ci_p2 = sharpe(strat_p2), bootstrap_ci(strat_p2)\n",
    "\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Strategy':<25} {'Trades':>8} {'PnL':>10} {'Sharpe':>10} {'95% CI':>16}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Buy & Hold':<25} {len(y_test):>8} {np.sum(strat_bh):>+9.1f}% {sharpe_bh:>10.2f} [{ci_bh[0]:.2f}, {ci_bh[1]:.2f}]\")\n",
    "print(f\"{'XGBoost -> Point':<25} {np.sum(decisions_p1):>8} {np.sum(strat_p1):>+9.1f}% {sharpe_p1:>10.2f} [{ci_p1[0]:.2f}, {ci_p1[1]:.2f}]\")\n",
    "print(f\"{'XGBoost -> Distribution':<25} {np.sum(decisions_p2):>8} {np.sum(strat_p2):>+9.1f}% {sharpe_p2:>10.2f} [{ci_p2[0]:.2f}, {ci_p2[1]:.2f}]\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nDistribution vs Point: {(sharpe_p2/sharpe_p1 - 1)*100:+.0f}% Sharpe improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Cumulative PnL\n",
    "ax = axes[0]\n",
    "days = np.arange(len(y_test))\n",
    "ax.plot(days, np.cumsum(strat_bh), 'k-', alpha=0.5, lw=1.5, label=f'Buy & Hold ({sharpe_bh:.2f})')\n",
    "ax.plot(days, np.cumsum(strat_p1), 'r-', lw=2, label=f'Point Prediction ({sharpe_p1:.2f})')\n",
    "ax.plot(days, np.cumsum(strat_p2), 'b-', lw=2, label=f'Distribution ({sharpe_p2:.2f})')\n",
    "ax.axhline(0, color='gray', ls=':', lw=1)\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Cumulative PnL (%)')\n",
    "ax.set_title('Cumulative Returns (Sharpe in legend)', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Sharpe comparison\n",
    "ax = axes[1]\n",
    "x = [0, 1, 2]\n",
    "bars = ax.bar(x, [sharpe_bh, sharpe_p1, sharpe_p2], color=['gray', 'red', 'blue'], alpha=0.7)\n",
    "ax.errorbar(x, [sharpe_bh, sharpe_p1, sharpe_p2],\n",
    "            yerr=[[sharpe_bh-ci_bh[0], sharpe_p1-ci_p1[0], sharpe_p2-ci_p2[0]],\n",
    "                  [ci_bh[1]-sharpe_bh, ci_p1[1]-sharpe_p1, ci_p2[1]-sharpe_p2]],\n",
    "            fmt='none', color='black', capsize=5)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Buy & Hold', 'Point\\nPrediction', 'Distribution\\nPrediction'])\n",
    "ax.set_ylabel('Annualized Sharpe')\n",
    "ax.set_title('Risk-Adjusted Returns (95% CI)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for i, s in enumerate([sharpe_bh, sharpe_p1, sharpe_p2]):\n",
    "    ax.text(i, s + 0.15, f'{s:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Distribution Prediction Wins\n",
    "\n",
    "The VaR filter rejects trades where predicted return is positive but risk is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days where Pipeline 1 trades but Pipeline 2 doesn't\n",
    "rejected = decisions_p1 & ~decisions_p2\n",
    "print(f\"Days rejected by VaR filter: {np.sum(rejected)}\")\n",
    "print(f\"Mean return on rejected days: {np.mean(y_test[rejected]):+.3f}%\")\n",
    "print(f\"Std return on rejected days: {np.std(y_test[rejected]):.3f}%\")\n",
    "print()\n",
    "print(f\"Days kept by Pipeline 2: {np.sum(decisions_p2)}\")\n",
    "print(f\"Mean return on kept days: {np.mean(y_test[decisions_p2]):+.3f}%\")\n",
    "print(f\"Std return on kept days: {np.std(y_test[decisions_p2]):.3f}%\")\n",
    "print()\n",
    "print(\"The VaR filter removes high-volatility days with worse risk-adjusted returns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Pipeline | Output | Decision Rule | Result |\n",
    "|----------|--------|---------------|--------|\n",
    "| Point | E[return] | Long if E[X] > 0 | Trades often, captures market |\n",
    "| Distribution | (mu, delta, alpha, beta) | Long if E[X] > 0 AND VaR > -2% | Selective, better risk-adjusted |\n",
    "\n",
    "**Key insight**: Distribution prediction provides uncertainty information that enables risk-based filtering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}